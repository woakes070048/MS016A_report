\chapter{Dynamic cloud-based scaling web services}
\textbf{Keywords: Virtualization, Cloud computing, performance, scripting}

\subsection*{Abstract}

This report takes a look at the implementation of a dynamic setup in cloud-based
web-services that scale with the load. With the load balancer HAProxy and
implemented through OpenStack APIs.

\section{Introduction}

\subsubsection{Problem statement}

The given problem statement in this project was as follows:

\emph{Build a cloud-based web service which is able to adjust the number of
webservers based on the incoming rate of user requests.}

\section{Background}
Cloud computing is becoming more and more popular, and is being implemented
in many parts of the industry \cite{OpenStack:Users}. You can rent resources 
from large providers like Amazon which provides a public cloud infrastructure 
or by building your own cloud infrastructure. This can be done with open source 
tools like OpenStack. There is also a third alternative that is the hybrid cloud,
which enables easy transaction from using both a private cloud and public clouds.\\

Having these cloud infrastructures, make it possible to have services
that scale over multiple locations, and to utilize the resources that are
available. When having spanning clouds we can use this to our advantage 
and create solutions to create more sturdy solutions, that will scale web
services in a more cost efficient way.\\

Web services with many consumers or with a high demand for calculation power
will need to be able to use multiple servers to provide service to the clients.
The number of servers needed is proportionate to the number of visitors and
calculations needed to provide the service. If there is not enough servers to
handle the load, there will a result in long response times or even loss of
service.\\

To handle this we need a way of scaling the number of servers in a way that
will give the expected result for the consumers, but at the same time use the
bare minimum amount needed in able to save money.\\

This will make the basis for this chapter where we will look into a solution to
scale a web service over multiple servers in an OpenStack environment.

\subsection{Cloud solution with OpenStack}
OpenStack is a free open source cloud software, that can be used to provide
infrastructure as a service (IaaS). 
OpenStack proclaims to be one of the fastest growing open source communities in
the world, backed by some of the biggest names in the industry like
RedHat and HP \cite{OpenStack:2014}. It is built up of multiple services
where each is responsible to handle a part of the operation in the cloud. Most
notably of these are nova, which handles the instances it selves and the
communication with the vitalization hypervisor. There are a total of 13
services which handles everything from identities, storage, networking,
orchestration and much more.\\

OpenStack is a viable cloud solution due to the large scale implementation, and
the large community supporting further development. One of the features provided 
and result of the open source software are the APIs that are available. 
\textit{Python-novaclient} implementation that provides almost full integration
with nova. Other implementations for the other OpenStack services are also
available. Since OpenStack are implemented in Python, there has been more work
on these API implementations, than what you might expect from a open source
project. According to \cite{OpenStack:api_comparison} the nova API is
compatible with the implementation from Amazon (AWS). This means that it is
possible to use \textit{python-novaclient} also with AWS. This is powerful when
developing tools that are supposed to work with clouds.

\subsection{HAProxy for load balancing}
HAProxy (High Availability proxy) is a free, very fast and reliable solution offering
high availability, load balancing, and proxying for TCP and HTTP-based applications
\cite{haproxy:2014}. It is used by large sites like Reddit, Stack Overflow and
Twitter \cite{haproxy:they_use_it}. Some of the features it provides in the
latest version is native SSL/TLS termination, which is lacking from most other
freely available load balancers, full HTTP keep-alive, IPv6 support, health
checks and much more \cite{haproxy:2014}. There are other free load balancers
that can be used, such as apache with mod, nginx, pound and varnish. Varnish is
mostly used only for caching and does not support SSL/TLS termination. HAProxy
appears to be a de facto standard when it comes to open source load
balancers.\\

These solutions creates a background for the solution to be created that can
make a service scale in a cloud environment. All this so we can save money, and
serve solutions that will prevail with large amounts of requests.
It is also worth noting that it will not only save the provider money, but
ultimately lower energy usage that could lower the environmental impact of a
service.


\section{Approach}
This study will focus on creating a application that enables scaling of a web 
service in a cloud environment. It will explore the possibility of web scaling
by implementing the possibilities of OpenStack and HAProxy in a Python
application. 
This will make it possible to make an application that is tightly integrated
with both OpenStack and HAProxy and make good use of the tight integration.

\subsection{Setup}
To be able to develop a application for this study, there is a need for a setup
that will supported the needed features. This is provided with the usage of
OpenStack and HAProxy. The base setup will need to be based on at least 3
instances, where we have one load balancer, which should also run the Webscaler
application and the HAProxy software as shown in figure \ref{fig:overview}. We
also need at least one client to send requests to the instance, and at least
one backend instance which actually holds the website.

\begin{figure}[htp]
\centering
\makebox[\textwidth][c]{\includegraphics[width=0.8\textwidth]{chapter1/overview}}
\caption{\label{fig:overview}Overview of the setup}
\end{figure}

From the application it will be possible to connect with both the load balancer
and OpenStack, and one requirement for this is that the application must run at
the load balancer instance.



\subsection{OpenStack integration}
OpenStack provides excellent possibilities for integration when programming in
Python. With the use of \textit{python-novaclient} \cite{OpenStackNovaClient} 
it is possible to do almost anything you can do with nova through either the 
CLI or OpenStack Horizon.

It is to be expected that the integration can provide all the needed
functionality of handling the instances. This means that it is possible to
handle the creation of new instances and provide the needed information so that
OpenStack handles the installation of the needed software on the new servers.
This can be done through the usage of cloud-data which is served with a
metadata service provided by OpenStack.

With this the application can scale up completely new instances which is
configured for the service within a short amount of time. When the instances
are no longer needed, the integration can shutdown or delete the instance
altogether.

\subsection{HAProxy}
The integration part to OpenStack is only a small part for administering the
instances to be created, but a way to communicate and get information from
HAProxy is needed. It is possible to get data from HAProxy by issuing commands
to the socket interface. There is also a web interface which provides a
overview of the status of the proxy itself and the stats for each of the
services and backends provided. The interface \vref{fig:haproxy_web_stats} lists
every node and service provided, and shows the different metrics available.

\begin{figure}[htp]
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.3\textwidth]{chapter1/haproxy}}
\caption{\label{fig:haproxy_web_stats}HAProxy web console}
\end{figure}

Everything in this stats page is available from the command line with the use
of a local socket connection to the proxy \ref{haproxy_socat}.

\begin{lstlisting}[label=haproxy_socat,caption=Getting statistics from HAProxy
with sockets,numbers=none]
echo "show stat" | socat /var/run/haproxy/admin.sock stdio
\end{lstlisting}

The socket interface supports many different commands which will be useful to
create a integrated service. This includes setting the backends as
\textit{disable}, \textit{enable} or \textit{draining} which can administer
which backends that should be used. \textit{Draining} mode is specially useful
as what it does is to disable new connection to the proxy, but enables the
existing connections to finish. This is powerful when shutting down backends.

\subsection{Data collection: Acquiring and analysing results}
To enable the scaling there is a need to have a picture of the current state of
service. This is what the load balancer can give with the use of the statistics
given through the socket interface. There are many different metrics to look at
when the goal is to get the rate of user requests. It is possible to get metric
from the web-service, which shows the frontend of the load balancer, or the
backends which can show individual metrics for each backend. The data could be
total transfered bytes, or the more relevant sessions which gives both current
number of sessions for the hole service, or total over time.

For this study the most relevant is the total over time for the service. This
will enable the scaler application to calculate the difference over time and
present it as a rate of incoming requests. This should be done to calculate the
number of requests per second. Thereafter this metric can be used to calculate
the needed servers, when setting a baseline-limit for connections per server
per second.

The difference is then calculated with the following formula:
\begin{equation}
\frac{(newsessions) - (previoussessions)}{sleeptime} =
Sessions/second
\end{equation}

This can then base on the calculation of the needed servers:
\begin{equation}
\frac{ceil(lastdiff)}{server threshold} = needed servers
\end{equation}

This means that there are multiple metrics that need to be stored during the
lifetime of the scaling application.
\begin{itemize}
\item Timestamp
\item Acumulated sessions/requests
\item Difference between last acumulated
\item Needed machines
\item Active machines (Available in OpenStack)
\item Active machines in HAProxy
\end{itemize}

From the data collected it should be possible to show how the scaling is
progressing. The data should therefor be stored in a csv (comma separated)
file so it is possible to import the data into graphing programs, or a
spreadsheet program. Based on this it is possible to generate a picture of how
the process flow is unfolding.

The data could be gathered on a rapid scale, but since it takes time for new
machines to be created or started, this needs to be taken into account. How
rapid the data gathering and scaling should be done is not that important,
since the data will be gathered on an average between the datapoints. A
timeframe of one minute is therefore chosen as it will be enough time to get a
good average, but also enough time for new machines to come up.

\subsection{Simulation for presentation}
To test how the load balancer and the webbalancer application will work during
load, a simulation is needed. The needed function for the simulation is the
possibility to vary the amount of requests to the load balancer. In the first
place the simulation will use httperf to generate load on the load balancer,
but since a variation is needed, this can be implemented by running multiple
httperf. This is implemented as \ref{simulator}.

\lstinputlisting[label=simulator, caption=Simulator of request increased and
descreased, numbers=none]{chapter1/simulator.txt}

With the results presented by the application it will be possible to see a
correlation between the needed scaling of servers based on the incoming http
requests.\\

With this approach it will be possible to create a webscaler by this design
that can scale up new instances in OpenStack based on the number of requests
gathered from HAProxy. It is a reactive design that will scale the machines
after the needed resources. The servicelevel will therefore depend on the
threshold that is set for one server. This is of course a limitation to the
design, and could be resolved by over provisioning or by predicting the needed
level of resources. That would be more of a proactive approach, and not a
reactive approach as this study intends.

\section{Result}
%What happened
This study presents a Webscaler written in Python that integrates into
OpenStack Nova and uses the load balancer HAProxy.

\subsection{Program flow}

\subsection{Launching instances from Python with nova}

\subsection{Automatic configuration of }
\section{Analysis}
 %Look at the data
\begin{figure}[htp]
%\centering
%\includegraphics[scale=0.6]{chapter1/server_scaling}
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.25\textwidth]{chapter1/server_scaling_with_requests_legend}}
\caption{\label{fig:server_scaling}Scaling of servers}
\end{figure}

\section{Discussion and conclusion}
% Why did i not use MLN
\subsection{Improvements}

\subsection{Conclusion}

\section{Appendix}
\lstinputlisting[label=haproxy.cfg,caption=HAProxy configuration file jinja template]
{chapter1/Webscaler/etc/haproxy.cfg}
